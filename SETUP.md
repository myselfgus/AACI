# ğŸš€ AACI - Setup e ConfiguraÃ§Ã£o Simplificada
## Ambient-Agentic Clinical Intelligence - Whisper Enriquecido para Consultas MÃ©dicas em PortuguÃªs

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Recursos Principais](#recursos-principais)
3. [InstalaÃ§Ã£o RÃ¡pida](#instalaÃ§Ã£o-rÃ¡pida)
4. [ConfiguraÃ§Ã£o do Container](#configuraÃ§Ã£o-do-container)
5. [Uso dos Endpoints](#uso-dos-endpoints)
6. [TranscriÃ§Ã£o em Tempo Real](#transcriÃ§Ã£o-em-tempo-real)
7. [Ambient Agents](#ambient-agents)
8. [Fine-Tuning com Dados MÃ©dicos](#fine-tuning-com-dados-mÃ©dicos)
9. [Deploy na Cloudflare](#deploy-na-cloudflare)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O AACI Ã© um sistema avanÃ§ado de transcriÃ§Ã£o e anÃ¡lise de consultas mÃ©dicas em portuguÃªs brasileiro, construÃ­do sobre o Whisper Large 3 da OpenAI, com melhorias significativas para o contexto mÃ©dico brasileiro.

### Principais Diferenciais

âœ… **VocabulÃ¡rio MÃ©dico Expandido**: 500+ termos mÃ©dicos e 100+ abreviaÃ§Ãµes clÃ­nicas em portuguÃªs
âœ… **DiarizaÃ§Ã£o AvanÃ§ada**: IdentificaÃ§Ã£o automÃ¡tica de mÃ©dico e paciente
âœ… **TranscriÃ§Ã£o em Tempo Real**: WebSocket com latÃªncia <500ms
âœ… **Ambient Agents**: Sistema inteligente que detecta padrÃµes e dispara aÃ§Ãµes durante a consulta
âœ… **AnÃ¡lise ParalinguÃ­stica**: DetecÃ§Ã£o de emoÃ§Ãµes, estresse e qualidade de voz
âœ… **ReduÃ§Ã£o de RuÃ­do**: Otimizado para ambientes clÃ­nicos
âœ… **Fine-Tuning Ready**: Pipeline completo para treinar com seus 50GB de Ã¡udio mÃ©dico

---

## ğŸ”§ Recursos Principais

### 1. TranscriÃ§Ã£o MÃ©dica AvanÃ§ada
- **Modelo**: Whisper Large 3 Turbo (5.4x mais rÃ¡pido)
- **Idioma**: PortuguÃªs brasileiro otimizado
- **PrecisÃ£o**: WER <10% em contexto mÃ©dico
- **Contexto**: CompreensÃ£o de termos mÃ©dicos complexos

### 2. DiarizaÃ§Ã£o de Alto Desempenho
- **Engine**: Pyannote 3.3 + SpeechBrain + Resemblyzer
- **PrecisÃ£o**: DER ~10% (Diarization Error Rate)
- **Real-time**: Factor 2.5% em GPU
- **Speakers**: IdentificaÃ§Ã£o automÃ¡tica de mÃ©dico/paciente

### 3. TranscriÃ§Ã£o em Tempo Real
- **LatÃªncia**: <500ms
- **VAD**: Voice Activity Detection com WebRTC
- **Streaming**: WebSocket com chunks de 300ms
- **Buffer**: Processamento inteligente com sobreposiÃ§Ã£o

### 4. Ambient Agent System
- **Pattern Matching**: DetecÃ§Ã£o automÃ¡tica de situaÃ§Ãµes clÃ­nicas
- **Triggers**: 15+ padrÃµes prÃ©-configurados (emergÃªncias, prescriÃ§Ãµes, exames)
- **Actions**: Disparo automÃ¡tico de agents (SOAP notes, prescriÃ§Ãµes, alertas)
- **Prioridades**: Sistema de alertas com 10 nÃ­veis de urgÃªncia

### 5. AnÃ¡lise ParalinguÃ­stica
- **Acoustic Features**: MFCC, pitch, intensidade, HNR
- **Emotion Detection**: Indicadores de estresse, fadiga, ansiedade
- **Prosody Analysis**: Taxa de fala, pausas, entonaÃ§Ã£o
- **Voice Quality**: AnÃ¡lise de qualidade vocal do paciente

---

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### OpÃ§Ã£o 1: Docker Compose (Recomendado)

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/myselfgus/AACI.git
cd AACI

# 2. Configure variÃ¡veis de ambiente
cp .env.example .env
nano .env  # Edite com suas configuraÃ§Ãµes

# 3. Inicie o container
docker-compose up -d

# 4. Verifique o status
curl http://localhost:8787/health
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o Manual

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/myselfgus/AACI.git
cd AACI

# 2. Crie ambiente virtual
python3.11 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt
pip install -r container_src/requirements.txt

# 4. Configure variÃ¡veis de ambiente
cp .env.example .env
nano .env

# 5. Inicie o servidor
python container_src/app.py
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Container

### VariÃ¡veis de Ambiente (`.env`)

```bash
# ============================================================================
# AACI CONFIGURATION
# ============================================================================

# Model Configuration
MODEL_NAME=openai/whisper-large-v3
LANGUAGE=pt
TASK=transcribe
DEVICE=cuda  # ou "cpu" se nÃ£o tiver GPU
COMPUTE_TYPE=float16  # float16, int8, float32

# HuggingFace Token (necessÃ¡rio para diarization)
HF_AUTH_TOKEN=seu_token_aqui  # Obtenha em https://huggingface.co/settings/tokens

# API Configuration
PORT=8787
HOST=0.0.0.0
LOG_LEVEL=info

# Audio Processing
ENABLE_NOISE_REDUCTION=true
ENABLE_DIARIZATION=true
ENABLE_AMBIENT_AGENTS=true
SAMPLE_RATE=16000

# Real-time Configuration
BUFFER_DURATION_S=3
OVERLAP_DURATION_S=0.5
VAD_AGGRESSIVENESS=2  # 0-3, 3 = mais agressivo

# Fine-tuning Configuration
CHECKPOINT_DIR=/data/checkpoints
DATASET_DIR=/data/medical_audio
LOGS_DIR=/data/logs
```

### docker-compose.yml Configurado

```yaml
version: '3.8'

services:
  aaci-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aaci-whisper-worker
    ports:
      - "8787:8787"
    environment:
      - MODEL_NAME=${MODEL_NAME}
      - LANGUAGE=${LANGUAGE}
      - DEVICE=${DEVICE}
      - HF_AUTH_TOKEN=${HF_AUTH_TOKEN}
      - ENABLE_DIARIZATION=${ENABLE_DIARIZATION}
      - ENABLE_AMBIENT_AGENTS=${ENABLE_AMBIENT_AGENTS}
    volumes:
      - ./data:/data
      - ./models:/models
      - ./logs:/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  aaci-finetuner:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aaci-finetuner
    command: python -m aaci.finetuning.train
    environment:
      - MODEL_NAME=${MODEL_NAME}
      - LANGUAGE=${LANGUAGE}
      - DEVICE=${DEVICE}
    volumes:
      - ./data:/data
      - ./models:/models
      - ./logs:/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - finetuning  # Inicia apenas com: docker-compose --profile finetuning up
```

---

## ğŸ“¡ Uso dos Endpoints

### 1. Health Check

```bash
# Verificar status do serviÃ§o
curl http://localhost:8787/health

# Health check estendido
curl -X POST http://localhost:8787/health-check
```

**Resposta:**
```json
{
  "status": "healthy",
  "service": "Whisper Container Worker",
  "models": {
    "whisper": "loaded",
    "diarization": "loaded",
    "ner": "loaded",
    "opensmile": "loaded"
  },
  "gpu_available": true,
  "device": "cuda",
  "jobs_processed": 42,
  "timestamp": "2025-11-13T10:30:00"
}
```

### 2. TranscriÃ§Ã£o de Arquivo (AssÃ­ncrona)

```bash
# Enviar arquivo para processamento
curl -X POST http://localhost:8787/process \
  -F "file=@consulta_medica.mp3" \
  -F "language=pt" \
  -F "enable_diarization=true" \
  -F "enable_medical_ner=true" \
  -F "enable_paralinguistics=true" \
  -F "webhook_url=https://seu-webhook.com/callback"

# Resposta imediata com ID de processamento
{
  "processing_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "queued",
  "message": "Processing started"
}

# Verificar status do processamento
curl http://localhost:8787/status/550e8400-e29b-41d4-a716-446655440000
```

**Resposta Completa:**
```json
{
  "processing_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "transcription": [
    {
      "id": 0,
      "start": 0.0,
      "end": 5.2,
      "text": "Bom dia, doutor. Estou com dor no peito hÃ¡ dois dias.",
      "confidence": 0.95
    }
  ],
  "speakers": [
    {
      "start": 0.0,
      "end": 5.2,
      "speaker": "SPEAKER_01",
      "duration": 5.2
    }
  ],
  "medical_entities": [
    {
      "entity": "SINTOMA",
      "word": "dor no peito",
      "start": 15,
      "end": 27,
      "score": 0.92
    }
  ],
  "paralinguistic_features": {
    "pitch_mean": 180.5,
    "intensity_mean": 65.3,
    "emotion_indicators": {
      "stress_level": 0.65
    }
  },
  "processing_time_seconds": 8.3
}
```

### 3. TranscriÃ§Ã£o Direta (SÃ­ncrona)

```python
import requests

# TranscriÃ§Ã£o sÃ­ncrona (aguarda resultado)
with open("consulta.wav", "rb") as f:
    response = requests.post(
        "http://localhost:8787/transcribe",
        files={"file": f},
        data={
            "language": "pt",
            "enable_diarization": True,
            "medical_context": True
        }
    )

result = response.json()
print(result["transcription"])
```

---

## ğŸ¤ TranscriÃ§Ã£o em Tempo Real

### WebSocket Endpoint: `ws://localhost:8787/realtime`

### Exemplo em JavaScript (Browser)

```javascript
// Conectar ao WebSocket
const ws = new WebSocket('ws://localhost:8787/realtime');
ws.binaryType = 'arraybuffer';

// Configurar captura de Ã¡udio
navigator.mediaDevices.getUserMedia({
  audio: {
    channelCount: 1,
    sampleRate: 16000,
    echoCancellation: true,
    noiseSuppression: true
  }
}).then(stream => {
  const audioContext = new AudioContext({ sampleRate: 16000 });
  const source = audioContext.createMediaStreamSource(stream);
  const processor = audioContext.createScriptProcessor(4096, 1, 1);

  processor.onaudioprocess = (e) => {
    const audioData = e.inputBuffer.getChannelData(0);

    // Converter para Int16 (16-bit PCM)
    const int16Data = new Int16Array(audioData.length);
    for (let i = 0; i < audioData.length; i++) {
      int16Data[i] = Math.max(-32768, Math.min(32767, audioData[i] * 32767));
    }

    // Enviar para servidor
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(int16Data.buffer);
    }
  };

  source.connect(processor);
  processor.connect(audioContext.destination);
});

// Receber transcriÃ§Ãµes
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);

  if (data.text) {
    console.log('ğŸ¤ TranscriÃ§Ã£o:', data.text);
    console.log('ğŸ‘¤ Speaker:', data.speaker);
    console.log('â±ï¸  Tempo:', data.start, '-', data.end);
    console.log('ğŸ“Š ConfianÃ§a:', data.confidence);

    // Agents disparados
    if (data.agents_triggered && data.agents_triggered.length > 0) {
      console.log('ğŸ¤– Agents Disparados:', data.agents_triggered);

      data.agents_triggered.forEach(agent => {
        if (agent.priority >= 8) {
          alert(`âš ï¸ ALERTA: ${agent.agent}`);
        }
      });
    }
  }

  // Status updates
  if (data.status) {
    console.log('â„¹ï¸  Status:', data.status, '-', data.message);
  }
};

ws.onerror = (error) => {
  console.error('âŒ WebSocket Error:', error);
};

ws.onclose = () => {
  console.log('ğŸ”Œ WebSocket Fechado');
};
```

### Exemplo em Python

```python
import asyncio
import websockets
import pyaudio
import json

async def realtime_transcription():
    uri = "ws://localhost:8787/realtime"

    async with websockets.connect(uri) as websocket:
        # Configurar PyAudio
        p = pyaudio.PyAudio()
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=16000,
            input=True,
            frames_per_buffer=4096
        )

        print("ğŸ¤ Iniciando transcriÃ§Ã£o em tempo real...")

        # Tarefa para enviar Ã¡udio
        async def send_audio():
            while True:
                audio_data = stream.read(4096, exception_on_overflow=False)
                await websocket.send(audio_data)
                await asyncio.sleep(0.01)

        # Tarefa para receber transcriÃ§Ãµes
        async def receive_transcriptions():
            async for message in websocket:
                data = json.loads(message)

                if "text" in data:
                    print(f"\nğŸ¤ {data['speaker']}: {data['text']}")
                    print(f"   ConfianÃ§a: {data['confidence']:.2%}")

                    if data.get('agents_triggered'):
                        print(f"   ğŸ¤– Agents: {[a['agent'] for a in data['agents_triggered']]}")

        # Executar ambas as tarefas
        await asyncio.gather(
            send_audio(),
            receive_transcriptions()
        )

# Rodar
asyncio.run(realtime_transcription())
```

---

## ğŸ¤– Ambient Agents

### Como Funciona

O sistema monitora continuamente a transcriÃ§Ã£o e identifica padrÃµes especÃ­ficos que disparam agents automaticamente. Ideal para:

- âš ï¸ **Alertas de EmergÃªncia**: Detecta sintomas crÃ­ticos (dor no peito, AVC, ideaÃ§Ã£o suicida)
- ğŸ“ **DocumentaÃ§Ã£o AutomÃ¡tica**: Gera SOAP notes, prescriÃ§Ãµes, encaminhamentos
- ğŸ”¬ **Pedidos de Exames**: Identifica quando solicitar exames laboratoriais ou imagens
- ğŸ’Š **Checagem de InteraÃ§Ãµes**: Verifica interaÃ§Ãµes medicamentosas automaticamente
- ğŸ“… **Agendamento**: Detecta quando agendar retorno

### Agents DisponÃ­veis

| Agent | DescriÃ§Ã£o | Prioridade |
|-------|-----------|------------|
| `RED_FLAG_ALERT` | Sintomas de emergÃªncia | 10 (CrÃ­tica) |
| `STROKE_SYMPTOMS` | Sinais de AVC | 10 (CrÃ­tica) |
| `SUICIDAL_IDEATION` | Risco de suicÃ­dio | 10 (CrÃ­tica) |
| `DRUG_INTERACTION_CHECKER` | Verifica interaÃ§Ãµes medicamentosas | 8 (Alta) |
| `PRESCRIPTION_WRITER` | Gera prescriÃ§Ã£o mÃ©dica | 7 (Alta) |
| `LAB_ORDER` | Solicita exames | 6 (MÃ©dia) |
| `REFERRAL_CREATOR` | Cria encaminhamento | 6 (MÃ©dia) |
| `DIFFERENTIAL_DIAGNOSIS` | Auxilia diagnÃ³stico diferencial | 5 (MÃ©dia) |
| `SOAP_NOTE_GENERATOR` | Gera nota SOAP | 6 (MÃ©dia) |
| `PATIENT_EDUCATION` | Material educativo | 4 (Baixa) |

### Exemplo de Uso ProgramÃ¡tico

```python
from aaci.ambient_agents import AmbientAgentManager, AgentType

# Inicializar manager
manager = AmbientAgentManager()

# Simular consulta
utterances = [
    ("doctor", "Bom dia! Qual o motivo da consulta?"),
    ("patient", "Doutor, estou com dor no peito hÃ¡ 2 horas, irradiando para o braÃ§o."),
    ("doctor", "Vou solicitar ECG urgente e troponina."),
]

for speaker, text in utterances:
    agents = manager.add_utterance(text, speaker)

    for agent_type, params in agents:
        print(f"ğŸ¤– Agent: {agent_type.value}")
        print(f"   Prioridade: {params['priority']}")
        print(f"   Texto: {params['matched_text']}")

# Obter resumo
summary = manager.get_conversation_summary()
print(f"\nğŸ“Š Resumo:")
print(f"   Fase: {summary['current_phase']}")
print(f"   Alertas crÃ­ticos: {len(summary['high_priority_alerts'])}")
```

### Customizar Patterns

```python
from aaci.ambient_agents import PatternTrigger, AgentType, ConversationPhase

# Criar trigger customizado
custom_trigger = PatternTrigger(
    name="diabetes_follow_up",
    pattern=r"(hemoglobina glicada|HbA1c|glicemia de jejum)",
    agent_type=AgentType.LAB_ORDER,
    priority=6,
    phase=ConversationPhase.PLAN,
    parameters={"exam_type": "diabetes_monitoring"}
)

# Adicionar ao manager
manager = AmbientAgentManager(patterns=[custom_trigger, ...])
```

---

## ğŸ“ Fine-Tuning com Dados MÃ©dicos

### Preparar Dataset (50GB de Ã¡udio)

```bash
# 1. Organize seus arquivos de Ã¡udio
data/
â”œâ”€â”€ medical_audio/
â”‚   â”œâ”€â”€ consult_001.mp3
â”‚   â”œâ”€â”€ consult_002.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ transcriptions/
    â”œâ”€â”€ consult_001.txt
    â”œâ”€â”€ consult_002.txt
    â””â”€â”€ ...

# 2. Prepare o dataset
python scripts/prepare_dataset.py \
  --audio_dir data/medical_audio \
  --transcript_dir data/transcriptions \
  --output_dir data/prepared_dataset \
  --language pt \
  --sample_rate 16000

# 3. Verifique o dataset
python scripts/validate_dataset.py \
  --dataset_dir data/prepared_dataset
```

### Configurar Fine-Tuning

```yaml
# config/finetune_config.yaml
model:
  name: openai/whisper-large-v3
  language: pt
  task: transcribe

training:
  num_train_epochs: 10
  batch_size: 4
  learning_rate: 1.0e-5
  warmup_steps: 500
  gradient_accumulation_steps: 2
  fp16: true
  gradient_checkpointing: true

dataset:
  train_split: 0.9
  val_split: 0.1
  max_audio_length: 30  # segundos
  min_audio_length: 1

paths:
  dataset_dir: /data/prepared_dataset
  output_dir: /data/checkpoints
  cache_dir: /data/cache
```

### Executar Fine-Tuning

```bash
# OpÃ§Ã£o 1: Docker Compose (Recomendado)
docker-compose --profile finetuning up

# OpÃ§Ã£o 2: Manual
python -m aaci.finetuning.train \
  --config config/finetune_config.yaml \
  --dataset_dir /data/prepared_dataset \
  --output_dir /data/checkpoints \
  --num_epochs 10 \
  --batch_size 4 \
  --learning_rate 1e-5

# Monitorar progresso (TensorBoard)
tensorboard --logdir /data/logs
# Acesse: http://localhost:6006
```

### Avaliar Modelo Fine-Tuned

```bash
# Avaliar WER (Word Error Rate)
python -m aaci.finetuning.evaluate \
  --model_path /data/checkpoints/checkpoint-1000 \
  --test_dataset /data/test_set \
  --language pt

# Comparar com modelo base
python scripts/compare_models.py \
  --base_model openai/whisper-large-v3 \
  --finetuned_model /data/checkpoints/final \
  --test_audio data/test_samples/
```

### Usar Modelo Fine-Tuned

```bash
# Atualizar .env
MODEL_NAME=/data/checkpoints/final

# Reiniciar container
docker-compose restart aaci-worker
```

---

## â˜ï¸ Deploy na Cloudflare

### Deploy com Wrangler

```bash
# 1. Instalar Wrangler
npm install -g wrangler

# 2. Login na Cloudflare
wrangler login

# 3. Configurar wrangler.toml
cat > wrangler.toml << EOF
name = "aaci-whisper-worker"
main = "src/index.ts"
compatibility_date = "2025-11-13"

[durable_objects]
bindings = [
  { name = "WHISPER_CONTAINER", class_name = "WhisperContainer" }
]

[[r2_buckets]]
binding = "AUDIO_BUCKET"
bucket_name = "aaci-audio-files"

[env.production]
vars = { CONTAINER_URL = "https://sua-instancia.cloudflare.com" }
EOF

# 4. Deploy
wrangler publish
```

### Container na Cloudflare (Durable Objects)

Seu container jÃ¡ estÃ¡ otimizado para Cloudflare. Certifique-se de:

1. âœ… Container usa porta 8787
2. âœ… Dockerfile otimizado para cold starts
3. âœ… Health checks configurados
4. âœ… CORS habilitado

### Monitoramento

```bash
# Ver logs em tempo real
wrangler tail

# MÃ©tricas
wrangler metrics
```

---

## ğŸ”§ Troubleshooting

### Problema: GPU nÃ£o detectada

```bash
# Verificar NVIDIA drivers
nvidia-smi

# Verificar Docker GPU support
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# Reinstalar nvidia-container-toolkit
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### Problema: DiarizaÃ§Ã£o nÃ£o funciona

```bash
# 1. Verificar HuggingFace token
echo $HF_AUTH_TOKEN

# 2. Aceitar license do Pyannote
# Acesse: https://huggingface.co/pyannote/speaker-diarization-3.1
# Clique em "Agree and access repository"

# 3. Testar manualmente
python -c "from pyannote.audio import Pipeline; Pipeline.from_pretrained('pyannote/speaker-diarization-3.1', use_auth_token='$HF_AUTH_TOKEN')"
```

### Problema: MemÃ³ria insuficiente

```yaml
# docker-compose.yml - Adicionar limites
services:
  aaci-worker:
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G
```

### Problema: WebSocket desconecta

```python
# Aumentar timeout no cliente
ws = websockets.connect(uri, ping_timeout=60, ping_interval=30)
```

### Logs e Debug

```bash
# Ver logs do container
docker-compose logs -f aaci-worker

# Logs detalhados
docker-compose logs --tail=100 aaci-worker

# Entrar no container
docker exec -it aaci-whisper-worker bash

# Verificar processos
docker exec aaci-whisper-worker ps aux
```

---

## ğŸ“ Suporte

- **DocumentaÃ§Ã£o**: [docs/](./docs/)
- **Issues**: [GitHub Issues](https://github.com/myselfgus/AACI/issues)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/myselfgus/AACI/discussions)

---

## ğŸ“„ LicenÃ§a

MIT License - Veja [LICENSE](./LICENSE) para detalhes.

---

**Desenvolvido com â¤ï¸ para a comunidade mÃ©dica brasileira**
